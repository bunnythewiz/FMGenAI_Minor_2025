# -*- coding: utf-8 -*-
"""FM&GAI_B_2

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1pQ_wHFx1QX9RY9_bj5Mf_CnskpbGHv0d

# Robustness to Messy Inputs

## Install required packages
"""

# Install required packages
# !pip install -q openai pandas matplotlib seaborn numpy

import json
import csv
import random
import re
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from typing import List, Dict, Tuple
import unicodedata
from google.colab import files
import io

# Set random seed for reproducibility
random.seed(42)
np.random.seed(42)

"""## NoiseGenerator"""

class NoiseGenerator:
    """Generate different types of noise for text inputs"""

    # Keyboard-adjacent substitutions for typos
    KEYBOARD_MAP = {
        'a': ['s', 'q', 'w'], 'b': ['v', 'g', 'h', 'n'], 'c': ['x', 'd', 'f', 'v'],
        'd': ['s', 'e', 'r', 'f', 'c', 'x'], 'e': ['w', 's', 'd', 'r'],
        'f': ['d', 'r', 't', 'g', 'c', 'v'], 'g': ['f', 't', 'y', 'h', 'v', 'b'],
        'h': ['g', 'y', 'u', 'j', 'b', 'n'], 'i': ['u', 'j', 'k', 'o'],
        'j': ['h', 'u', 'i', 'k', 'n', 'm'], 'k': ['j', 'i', 'o', 'l', 'm'],
        'l': ['k', 'o', 'p'], 'm': ['n', 'j', 'k'], 'n': ['b', 'h', 'j', 'm'],
        'o': ['i', 'k', 'l', 'p'], 'p': ['o', 'l'], 'q': ['w', 'a', 's'],
        'r': ['e', 'd', 'f', 't'], 's': ['a', 'q', 'w', 'd', 'x', 'z'],
        't': ['r', 'f', 'g', 'y'], 'u': ['y', 'h', 'j', 'i'],
        'v': ['c', 'f', 'g', 'b'], 'w': ['q', 'a', 's', 'e'],
        'x': ['z', 's', 'd', 'c'], 'y': ['t', 'g', 'h', 'u'],
        'z': ['x', 's', 'a']
    }

    # Unicode confusables (safe, common ones)
    CONFUSABLES = {
        'a': ['–∞', '…ë'], 'e': ['–µ', 'Œµ'], 'o': ['–æ', 'Œø'], 'p': ['—Ä', 'œÅ'],
        'c': ['—Å', 'œ≤'], 'x': ['—Ö', 'œá'], 'y': ['—É', 'Œ≥'], 'i': ['—ñ', 'Œπ'],
        'A': ['–ê', 'Œë'], 'B': ['–í', 'Œí'], 'E': ['–ï', 'Œï'], 'H': ['–ù', 'Œó'],
        'I': ['–Ü', 'Œô'], 'K': ['–ö', 'Œö'], 'M': ['–ú', 'Œú'], 'N': ['Œù'],
        'O': ['–û', 'Œü'], 'P': ['–†', 'Œ°'], 'T': ['–¢', 'Œ§'], 'X': ['–•', 'Œß'],
        'Y': ['–£', 'Œ•'], 'Z': ['Œñ'], '0': ['–û', 'Œü'], '1': ['–Ü', 'l']
    }

    # Neutral emoji for sprinkling
    NEUTRAL_EMOJI = ['üìù', 'üí≠', 'üîç', 'üìä', 'üí°', 'üéØ', 'üìå', '‚ú®', 'üî§', 'üìã']

    @staticmethod
    def add_typos(text: str, strength: str) -> str:
        """Add keyboard-adjacent typos"""
        words = text.split()
        prob = 0.1 if strength == "mild" else 0.25

        result = []
        for word in words:
            if random.random() < prob and len(word) > 2:
                # Choose random position
                pos = random.randint(0, len(word) - 1)
                char = word[pos].lower()

                if char in NoiseGenerator.KEYBOARD_MAP:
                    # Substitution
                    new_char = random.choice(NoiseGenerator.KEYBOARD_MAP[char])
                    word = word[:pos] + new_char + word[pos+1:]
                elif random.random() < 0.3:
                    # Insertion
                    insert_char = random.choice('abcdefghijklmnopqrstuvwxyz')
                    word = word[:pos] + insert_char + word[pos:]
            result.append(word)

        return ' '.join(result)

    @staticmethod
    def add_spacing_punct(text: str, strength: str) -> str:
        """Add spacing and punctuation issues"""
        prob = 0.15 if strength == "mild" else 0.3

        # Add random spaces
        if random.random() < prob:
            words = text.split()
            for i in range(len(words)):
                if random.random() < 0.2:
                    words[i] = words[i] + ' ' * random.randint(1, 3)
            text = ' '.join(words)

        # Drop punctuation
        if random.random() < prob:
            text = re.sub(r'[,.]', '', text, count=random.randint(1, 3))

        # Collapse/expand spaces
        text = re.sub(r' +', ' ' * random.randint(1, 4), text)

        return text

    @staticmethod
    def add_unicode_confusables(text: str, strength: str) -> str:
        """Add unicode confusable characters"""
        prob = 0.1 if strength == "mild" else 0.2

        result = []
        for char in text:
            if char in NoiseGenerator.CONFUSABLES and random.random() < prob:
                result.append(random.choice(NoiseGenerator.CONFUSABLES[char]))
            else:
                result.append(char)

        return ''.join(result)

    @staticmethod
    def add_emoji(text: str, strength: str) -> str:
        """Add neutral emoji around entities"""
        words = text.split()
        prob = 0.1 if strength == "mild" else 0.2

        result = []
        for word in words:
            if random.random() < prob:
                emoji = random.choice(NoiseGenerator.NEUTRAL_EMOJI)
                if random.random() < 0.5:
                    result.append(emoji + word)
                else:
                    result.append(word + emoji)
            else:
                result.append(word)

        return ' '.join(result)

"""## QA dataset"""

# Create clean QA dataset
def create_clean_dataset():
    """Create 50 clean short QA pairs"""
    qa_pairs = [
        ("What is the capital of France?", "Paris"),
        ("What is 7 + 8?", "15"),
        ("What color do you get mixing red and blue?", "Purple"),
        ("What is the largest planet in our solar system?", "Jupiter"),
        ("What year did World War II end?", "1945"),
        ("What is the chemical symbol for gold?", "Au"),
        ("What is the smallest prime number?", "2"),
        ("What ocean is west of California?", "Pacific Ocean"),
        ("What is the square root of 64?", "8"),
        ("What gas do plants absorb from the atmosphere?", "Carbon dioxide"),
        ("What is the hardest natural substance?", "Diamond"),
        ("What is the currency of Japan?", "Yen"),
        ("What planet is known as the Red Planet?", "Mars"),
        ("What is 12 √ó 5?", "60"),
        ("What is the longest river in the world?", "Nile River"),
        ("What element has the atomic number 1?", "Hydrogen"),
        ("What is the capital of Australia?", "Canberra"),
        ("What is 100 √∑ 4?", "25"),
        ("What organ pumps blood through the body?", "Heart"),
        ("What is the fastest land animal?", "Cheetah"),
        ("What is H2O commonly known as?", "Water"),
        ("What is 9¬≤?", "81"),
        ("What country is famous for the pyramids?", "Egypt"),
        ("What is the boiling point of water in Celsius?", "100"),
        ("What gas makes up most of Earth's atmosphere?", "Nitrogen"),
        ("What is the capital of Canada?", "Ottawa"),
        ("What is 15 - 7?", "8"),
        ("What force keeps us on the ground?", "Gravity"),
        ("What is the largest mammal?", "Blue whale"),
        ("What metal is liquid at room temperature?", "Mercury"),
        ("What is the capital of Italy?", "Rome"),
        ("What is 6 √ó 9?", "54"),
        ("What do bees make?", "Honey"),
        ("What is the study of earthquakes called?", "Seismology"),
        ("What vitamin is produced by skin in sunlight?", "Vitamin D"),
        ("What is the capital of Germany?", "Berlin"),
        ("What is 144 √∑ 12?", "12"),
        ("What gas do we breathe in to live?", "Oxygen"),
        ("What is the smallest country in the world?", "Vatican City"),
        ("What temperature does water freeze at in Fahrenheit?", "32"),
        ("What is the capital of Spain?", "Madrid"),
        ("What is 8 + 7?", "15"),
        ("What animal is known as the king of the jungle?", "Lion"),
        ("What is the main ingredient in glass?", "Silicon dioxide"),
        ("What planet is closest to the sun?", "Mercury"),
        ("What is the capital of the United Kingdom?", "London"),
        ("What is 20% of 50?", "10"),
        ("What do caterpillars turn into?", "Butterflies"),
        ("What is the speed of light approximately?", "300,000 km/s"),
        ("What is the largest organ in the human body?", "Skin")
    ]

    return qa_pairs

# Create the dataset
clean_dataset = create_clean_dataset()
print(f"‚úÖ Created clean dataset with {len(clean_dataset)} QA pairs")

# Generate perturbed variants
def generate_perturbed_dataset(clean_data, noise_types, strengths):
    """Generate all perturbed variants"""
    perturbed_data = []

    noise_functions = {
        'typos': NoiseGenerator.add_typos,
        'spacing': NoiseGenerator.add_spacing_punct,
        'unicode': NoiseGenerator.add_unicode_confusables,
        'emoji': NoiseGenerator.add_emoji
    }

    # Add clean baseline
    for i, (question, answer) in enumerate(clean_data):
        perturbed_data.append({
            'id': i,
            'noise_type': 'clean',
            'noise_level': 'none',
            'prompt_in': question,
            'gold': answer,
            'pred': '',  # To be filled during evaluation
            'correct': -1  # To be filled during evaluation
        })

    # Add perturbed variants
    for noise_type in noise_types:
        for strength in strengths:
            for i, (question, answer) in enumerate(clean_data):
                noisy_question = noise_functions[noise_type](question, strength)
                perturbed_data.append({
                    'id': i,
                    'noise_type': noise_type,
                    'noise_level': strength,
                    'prompt_in': noisy_question,
                    'gold': answer,
                    'pred': '',
                    'correct': -1
                })

    return perturbed_data

# Generate the full dataset
noise_types = ['typos', 'spacing', 'unicode', 'emoji']
strengths = ['mild', 'severe']

full_dataset = generate_perturbed_dataset(clean_dataset, noise_types, strengths)
print(f"‚úÖ Generated {len(full_dataset)} total variants")

# Show some examples
print("\nüìù Example perturbed inputs:")
examples = [d for d in full_dataset if d['id'] == 0]  # First question variants
for ex in examples[:6]:  # Show first 6 variants
    print(f"{ex['noise_type']:8} ({ex['noise_level']:6}): {ex['prompt_in']}")

"""## SimpleLLMSimulator"""

# Simple LLM simulator (replace with actual API calls)
class SimpleLLMSimulator:
    """Simulate LLM responses for demonstration"""

    def __init__(self):
        # Simple answer mapping for simulation
        self.answer_map = {q.lower(): a for q, a in clean_dataset}

    def predict(self, question: str, robust_prompt: bool = False) -> str:
        """Simulate LLM prediction with noise robustness"""

        if robust_prompt:
            # Simulate better performance with robust prompting
            # Clean the input slightly for simulation
            clean_q = re.sub(r'[^\w\s?]', '', question.lower())
            clean_q = re.sub(r'\s+', ' ', clean_q).strip()

            # Look for partial matches
            for known_q, answer in self.answer_map.items():
                if self._similarity(clean_q, known_q) > 0.7:
                    return answer
        else:
            # Direct lookup (more sensitive to noise)
            clean_q = question.lower().strip()
            if clean_q in self.answer_map:
                return self.answer_map[clean_q]

            # Try partial matching
            for known_q, answer in self.answer_map.items():
                if self._similarity(clean_q, known_q) > 0.85:
                    return self.answer_map[known_q]

        # Return wrong answer for failed matches
        return "Unknown"

    def _similarity(self, s1: str, s2: str) -> float:
        """Simple similarity measure"""
        words1 = set(s1.split())
        words2 = set(s2.split())
        intersection = words1 & words2
        union = words1 | words2
        return len(intersection) / len(union) if union else 0

# Initialize simulator
llm = SimpleLLMSimulator()

"""## Baseline Evaluation"""

print("\nü§ñ Running baseline evaluation...")

# Evaluate baseline (without robust prompting)
for item in full_dataset:
    pred = llm.predict(item['prompt_in'], robust_prompt=False)
    item['pred'] = pred
    item['correct'] = 1 if pred.lower() == item['gold'].lower() else 0

# Calculate baseline results
def calculate_results(dataset):
    """Calculate accuracy by noise type and level"""
    results = {}

    for item in dataset:
        key = f"{item['noise_type']}_{item['noise_level']}"
        if key not in results:
            results[key] = {'correct': 0, 'total': 0}

        results[key]['correct'] += item['correct']
        results[key]['total'] += 1

    # Calculate accuracies
    for key in results:
        results[key]['accuracy'] = results[key]['correct'] / results[key]['total']

    return results

baseline_results = calculate_results(full_dataset)

# Display baseline results
print("\nüìä Baseline Results:")
print("=" * 40)
for key, stats in sorted(baseline_results.items()):
    acc = stats['accuracy'] * 100
    print(f"{key:15}: {acc:5.1f}% ({stats['correct']}/{stats['total']})")

"""## Robust Prompting Intervention"""

# Design robust prompting intervention
ROBUST_PROMPT_TEMPLATE = """
You may encounter text with typos, unusual spacing, Unicode characters, or emoji.
Focus on the semantic meaning and intent of the question, not the exact formatting.
Normalize the text mentally before answering.

Question: {question}

Provide only the direct answer without explanation:
"""

print("\nüõ°Ô∏è  Testing robust prompting intervention on subset...")

# Test robustness intervention on 20-item subset
subset_indices = list(range(20))  # First 20 questions
robust_dataset = [item for item in full_dataset if item['id'] in subset_indices]

# Re-evaluate with robust prompting
for item in robust_dataset:
    pred = llm.predict(item['prompt_in'], robust_prompt=True)
    item['pred_robust'] = pred
    item['correct_robust'] = 1 if pred.lower() == item['gold'].lower() else 0

# Calculate robust results
def calculate_robust_comparison(dataset):
    """Compare baseline vs robust results"""
    comparison = {}

    for item in dataset:
        key = f"{item['noise_type']}_{item['noise_level']}"
        if key not in comparison:
            comparison[key] = {
                'baseline_correct': 0, 'robust_correct': 0, 'total': 0
            }

        comparison[key]['baseline_correct'] += item['correct']
        comparison[key]['robust_correct'] += item['correct_robust']
        comparison[key]['total'] += 1

    # Calculate accuracies and improvements
    for key in comparison:
        stats = comparison[key]
        stats['baseline_acc'] = stats['baseline_correct'] / stats['total']
        stats['robust_acc'] = stats['robust_correct'] / stats['total']
        stats['improvement'] = stats['robust_acc'] - stats['baseline_acc']

    return comparison

robust_comparison = calculate_robust_comparison(robust_dataset)

print("\nüìà Robustness Intervention Results (20-item subset):")
print("=" * 60)
print(f"{'Condition':15} {'Baseline':>10} {'Robust':>10} {'Improvement':>12}")
print("-" * 60)

for key, stats in sorted(robust_comparison.items()):
    baseline_pct = stats['baseline_acc'] * 100
    robust_pct = stats['robust_acc'] * 100
    improvement = stats['improvement'] * 100
    print(f"{key:15} {baseline_pct:8.1f}% {robust_pct:8.1f}% {improvement:+10.1f}%")

"""## Visualization"""

# Create visualization
def create_heatmap():
    """Create heatmap visualization"""
    # Prepare data for heatmap
    noise_types = ['clean', 'typos', 'spacing', 'unicode', 'emoji']
    noise_levels = ['none', 'mild', 'severe']

    heatmap_data = np.zeros((len(noise_types), len(noise_levels)))

    for i, ntype in enumerate(noise_types):
        for j, nlevel in enumerate(noise_levels):
            if ntype == 'clean' and nlevel == 'none':
                key = 'clean_none'
            elif ntype != 'clean' and nlevel != 'none':
                key = f"{ntype}_{nlevel}"
            else:
                continue

            if key in baseline_results:
                heatmap_data[i, j] = baseline_results[key]['accuracy'] * 100

    # Create the heatmap
    plt.figure(figsize=(10, 6))
    mask = heatmap_data == 0

    sns.heatmap(
        heatmap_data,
        annot=True,
        fmt='.1f',
        cmap='RdYlGn',
        xticklabels=noise_levels,
        yticklabels=noise_types,
        mask=mask,
        cbar_kws={'label': 'Accuracy (%)'}
    )

    plt.title('LLM Robustness to Input Noise\n(Accuracy % by Noise Type and Strength)')
    plt.xlabel('Noise Strength')
    plt.ylabel('Noise Type')
    plt.tight_layout()
    plt.show()

create_heatmap()

"""## Error Taxonomy Analysis"""

# Error taxonomy analysis
def analyze_error_patterns(dataset):
    """Analyze error patterns by category"""

    error_categories = {
        'Semantic Understanding': [],
        'Character Recognition': [],
        'Spacing/Punctuation': [],
        'Format Confusion': [],
        'Complete Failure': []
    }

    # Sample some errors for taxonomy
    errors = [item for item in dataset if item['correct'] == 0][:20]

    for error in errors:
        original = clean_dataset[error['id']][0]  # Original question
        noisy = error['prompt_in']

        # Simple categorization logic
        if error['noise_type'] == 'unicode':
            error_categories['Character Recognition'].append({
                'original': original,
                'noisy': noisy,
                'type': error['noise_type'],
                'pred': error['pred']
            })
        elif error['noise_type'] == 'spacing':
            error_categories['Spacing/Punctuation'].append({
                'original': original,
                'noisy': noisy,
                'type': error['noise_type'],
                'pred': error['pred']
            })
        elif error['noise_type'] == 'typos':
            error_categories['Semantic Understanding'].append({
                'original': original,
                'noisy': noisy,
                'type': error['noise_type'],
                'pred': error['pred']
            })
        else:
            error_categories['Format Confusion'].append({
                'original': original,
                'noisy': noisy,
                'type': error['noise_type'],
                'pred': error['pred']
            })

    return error_categories

error_taxonomy = analyze_error_patterns(full_dataset)

print("\nüîç Error Taxonomy Analysis:")
print("=" * 50)

for category, errors in error_taxonomy.items():
    if errors:
        print(f"\n{category}:")
        example = errors[0]
        print(f"  Original: {example['original']}")
        print(f"  Noisy:    {example['noisy']}")
        print(f"  Predicted: {example['pred']}")
        print(f"  Count: {len(errors)} examples")

"""## Saving"""

# Save results to CSV
def save_results_csv():
    """Save results to downloadable CSV"""

    # Prepare CSV data
    csv_data = []
    for item in full_dataset:
        csv_data.append({
            'id': item['id'],
            'noise_type': item['noise_type'],
            'noise_level': item['noise_level'],
            'prompt_in': item['prompt_in'],
            'gold': item['gold'],
            'pred': item['pred'],
            'correct': item['correct']
        })

    # Convert to DataFrame and save
    df = pd.DataFrame(csv_data)

    # Save to CSV
    csv_filename = 'robustness_results.csv'
    df.to_csv(csv_filename, index=False)

    print(f"\nüíæ Results saved to {csv_filename}")

    # Download in Colab
    files.download(csv_filename)

    return df

results_df = save_results_csv()

"""## Summary"""

# Display summary statistics
print("\nüìã Summary Statistics:")
print("=" * 30)

clean_acc = baseline_results['clean_none']['accuracy'] * 100
print(f"Clean baseline accuracy: {clean_acc:.1f}%")

degradations = []
for noise_type in noise_types:
    for strength in strengths:
        key = f"{noise_type}_{strength}"
        if key in baseline_results:
            acc = baseline_results[key]['accuracy'] * 100
            degradation = clean_acc - acc
            degradations.append(degradation)
            print(f"{key:15}: {acc:5.1f}% (-{degradation:.1f} pts)")

avg_degradation = np.mean(degradations)
print(f"\nAverage degradation: {avg_degradation:.1f} percentage points")

# Create preprocessing snippet
preprocessing_code = '''
def preprocess_text(text: str) -> str:
    """Light preprocessing to improve robustness"""
    import re
    import unicodedata

    # Normalize unicode
    text = unicodedata.normalize('NFKD', text)

    # Remove extra whitespace
    text = re.sub(r'\\s+', ' ', text)

    # Remove emoji (optional)
    text = re.sub(r'[\\U0001F600-\\U0001F64F\\U0001F300-\\U0001F5FF\\U0001F680-\\U0001F6FF\\U0001F700-\\U0001F77F\\U0001F780-\\U0001F7FF\\U0001F800-\\U0001F8FF\\U0001F900-\\U0001F9FF\\U0001FA00-\\U0001FA6F\\U0001FA70-\\U0001FAFF\\U00002600-\\U000026FF\\U00002700-\\U000027BF]', '', text)

    return text.strip()
'''

print("\nüîß Preprocessing Snippet:")
print("=" * 30)
print(preprocessing_code)

print("\n‚úÖ Experiment completed!")
print("üìä Check the heatmap visualization above")
print("üíæ Download the robustness_results.csv file")
print("üìã Review the error taxonomy and summary statistics")

# Methods section information
print("\nüìù Methods Section Information:")
print("=" * 40)
print("Model: Claude Sonnet 4 (simulated)")
print("Decoding: Deterministic (temperature=0)")
print("Hardware: Google Colab (simulated)")
print("Dataset: 50 clean QA pairs")
print("Noise types: 4 (typos, spacing, unicode, emoji)")
print("Noise levels: 2 (mild, severe)")
print("Total variants: 450 (50 clean + 400 noisy)")
print("Robustness test: 20-item subset")
print("Evaluation metric: Exact match accuracy")